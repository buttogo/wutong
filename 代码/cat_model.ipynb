{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max.columns',None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import time\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,precision_recall_fscore_support,roc_curve,auc,roc_auc_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('A榜给选手数据/train_set.csv')\n",
    "train_label = pd.read_csv('A榜给选手数据/train_label.csv')\n",
    "result_predict_B = pd.read_csv('B榜给选手数据/result_predict_B.csv')\n",
    "result_predict_A = pd.read_csv('A榜给选手数据/result_predict_A.csv')\n",
    "\n",
    "train_set = train_set.merge(train_label,how='left',on='user_id')\n",
    "data = pd.concat([train_set,result_predict_B],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['X26'].fillna(-1,inplace=True)\n",
    "data['X27'].fillna(0,inplace=True)\n",
    "data['X38'].fillna(0,inplace=True)\n",
    "\n",
    "col_idx = data['X26'].value_counts()\n",
    "for idx in col_idx[col_idx < 10].index:\n",
    "    data['X26'] = data['X26'].replace(idx, -1)\n",
    "    data['X26'] = data['X26'].replace(idx, -1)\n",
    "\n",
    "for col in ['X1', 'X5']:\n",
    "    data[col] = pd.factorize(data[col])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['arpu_incre_1'] = data['X6'] - data['X7']\n",
    "data['arpu_incre_2'] = data['X6'] - data['X8']\n",
    "data['arpu_incre_3'] = data['X7'] - data['X8']\n",
    "data['arpu_rate_1'] = (data['X6'] - data['X7']) / (data['X7'] + 1)\n",
    "data['arpu_rate_2'] = (data['X6'] - data['X8']) / (data['X8'] + 1)\n",
    "data['arpu_rate_3'] = (data['X7'] - data['X8']) / (data['X8'] + 1)\n",
    "\n",
    "data['dou_incre_1'] = data['X9'] - data['X10']\n",
    "\n",
    "data['mou_incre_1'] = data['X12'] - data['X13']\n",
    "\n",
    "data['dangyue_arpu'] = data['X6'] / data['X15']\n",
    "data['dangyue_dou'] = data['X9'] / data['X16']\n",
    "data['dangyue_mou'] = data['X12'] / data['X17']\n",
    "data['mou_dou_1'] = data['X17'] / data['X16']\n",
    "data['taocan_arpu_1'] = data['X32'] / data['X15']\n",
    "data['taocan_arpu_2'] = data['X33'] / data['X15']\n",
    "\n",
    "data['yuyin_mean'] = (data['X18'] + data['X19'] + data['X20']) / 3\n",
    "data['liuliang_mean'] = (data['X21'] + data['X22'] + data['X23']) / 3\n",
    "\n",
    "data['yuyin_incre_1'] = data['X18'] - data['X19']\n",
    "\n",
    "data['liuliang_incre_1'] = data['X21'] - data['X22']\n",
    "\n",
    "data['baohe_mean'] = (data['X34'] + data['X35'] + data['X36']) / 3\n",
    "data['baohe_incre_1'] = data['X34'] - data['X35']\n",
    "\n",
    "data['dangyue_yuyin'] = data['X18'] / data['yuyin_mean']\n",
    "data['liuliang_yuyin'] = data['X21'] / data['liuliang_mean']\n",
    "data['dangyue_baohe'] = data['X34'] / data['baohe_mean']\n",
    "\n",
    "data['arpu_qushi'] = (data['X6'] - data['X8']) / data['X15']\n",
    "data['dou_qushi'] = (data['X9'] - data['X11']) / data['X16']\n",
    "data['mou_qushi'] = (data['X12'] - data['X14']) / data['X17']\n",
    "data['yuyin_qushi'] = (data['X20'] - data['X18']) / data['yuyin_mean']\n",
    "data['liuliang_qushi'] = (data['X23'] - data['X21']) / data['liuliang_mean']\n",
    "data['baohe_qushi'] = (data['X36'] - data['X34']) / data['baohe_mean']\n",
    "\n",
    "data['X38_flag'] = data['X38'].apply(lambda x: 1 if x>0 else 0)\n",
    "data['5G_num'] = data[['X38', 'X41', 'X42','X43']].sum(1)\n",
    "\n",
    "bins = [0,8,18,38,58,88,128,168,238,max(data['X33'])]\n",
    "data['X33_bin'] = pd.cut(data['X33'], bins,right=True,labels=False)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 23.03it/s]\n"
     ]
    }
   ],
   "source": [
    "cate_cols = ['X3','X5', 'X26','X33_bin']\n",
    "num_cols = ['X4', 'X15','X16', 'X17','X32','X33','X38','yuyin_mean','liuliang_mean','baohe_mean']\n",
    "\n",
    "from tqdm import tqdm\n",
    "for f in tqdm(cate_cols):\n",
    "    data[f + '_count'] = data[f].map(data[f].value_counts())\n",
    "    \n",
    "# 偏离值特征            \n",
    "for col in cate_cols:\n",
    "    for feature in num_cols:\n",
    "        tmp = data.groupby(col)[feature].agg([sum, min, max, np.mean,np.std]).reset_index()\n",
    "        tmp = pd.merge(data, tmp, on=col, how='left')\n",
    "        data['{}-mean_gb_{}'.format(feature, col)] = data[feature] - tmp['mean']\n",
    "        data['{}-min_gb_{}'.format(feature, col)] = data[feature] - tmp['min']\n",
    "        data['{}-max_gb_{}'.format(feature, col)] = data[feature] - tmp['max']\n",
    "        data['{}/sum_gb_{}'.format(feature, col)] = data[feature] / tmp['sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    112000\n",
      "1.0     28000\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data.drop(['X33_bin'],axis=1,inplace=True)\n",
    "\n",
    "data = data.replace(-np.inf, np.nan)\n",
    "data = data.replace(np.inf, np.nan)\n",
    "\n",
    "train_data = data[data.label.notna()].copy()\n",
    "test_data = data[data.label.isna()].copy()\n",
    "y_train = train_data['label'].copy()\n",
    "\n",
    "features = [f for f in train_data.columns if f not in ['user_id', 'product_no','label']]\n",
    "cat_features = ['X1', 'X3', 'X5', 'X24', 'X25', 'X26', 'X27', 'X28','X29', 'X30',\n",
    "                'X31', 'X37', 'X39', 'X40', 'X41', 'X42', 'X43','X38_flag']\n",
    "X = train_data[features].copy()\n",
    "X_test = test_data[features].copy()\n",
    "y = train_data['label'].copy()\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_classification(X, X_test, y, params, num_classes=2,\n",
    "                               folds=None, model_type='lgb',\n",
    "                               eval_metric='logloss', columns=None,\n",
    "                               plot_feature_importance=False,\n",
    "                               cat_features=[],\n",
    "                               model=None, verbose=10000,\n",
    "                               early_stopping_rounds=200,\n",
    "                               splits=None, n_folds=3):\n",
    "\n",
    "    start_time = time.time()\n",
    "    global y_pred_valid, y_pred\n",
    "\n",
    "    columns = X.columns if columns is None else columns\n",
    "    X_test = X_test[columns]\n",
    "    splits = folds.split(X, y) if splits is None else splits\n",
    "    n_splits = folds.n_splits if splits is None else n_folds\n",
    "\n",
    "    # to set up scoring parameters\n",
    "    metrics_dict = {\n",
    "        'logloss': {\n",
    "            'lgb_metric_name': 'logloss',\n",
    "            'xgb_metric_name': 'logloss',\n",
    "            'catboost_metric_name': 'Logloss',\n",
    "            'sklearn_scoring_function': metrics.log_loss\n",
    "        },\n",
    "        'lb_score_method': {\n",
    "            'sklearn_scoring_f1': metrics.f1_score,  \n",
    "            'sklearn_scoring_accuracy': metrics.accuracy_score,\n",
    "            'sklearn_scoring_auc': metrics.roc_auc_score\n",
    "        },\n",
    "    }\n",
    "    result_dict = {}\n",
    "\n",
    "    # out-of-fold predictions on train data\n",
    "    oof = np.zeros(shape=(len(X), num_classes))\n",
    "    # averaged predictions on train data\n",
    "    prediction = np.zeros(shape=(len(X_test), num_classes))\n",
    "    # list of scores on folds\n",
    "    acc_scores=[]\n",
    "    scores = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    # feature importance\n",
    "    feature_importance = pd.DataFrame()\n",
    "\n",
    "    # split and train on folds\n",
    "    for fold_n, (train_index, valid_index) in enumerate(splits):\n",
    "        if verbose:\n",
    "            print(f'Fold {fold_n + 1} started at {time.ctime()}')\n",
    "        if type(X) == np.ndarray:\n",
    "            X_train, X_valid = X[train_index], X[valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "        else:\n",
    "            X_train, X_valid = X[columns].iloc[train_index], X[columns].iloc[valid_index]\n",
    "            y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "        if model_type == 'lgb':\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            model.fit(X_train, y_train,\n",
    "                      eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                      categorical_feature = cat_features,\n",
    "                      eval_metric=metrics_dict[eval_metric]['lgb_metric_name'],\n",
    "                      verbose=verbose,\n",
    "                      early_stopping_rounds=early_stopping_rounds)\n",
    "\n",
    "            y_pred_valid = model.predict_proba(X_valid)\n",
    "            y_pred = model.predict_proba(X_test, num_iteration=model.best_iteration_)\n",
    "\n",
    "        if model_type == 'xgb':\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            model.fit(X_train, y_train,\n",
    "                      eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "                      eval_metric=metrics_dict[eval_metric]['xgb_metric_name'],\n",
    "                      verbose=bool(verbose),  # xgb verbose bool\n",
    "                      early_stopping_rounds=early_stopping_rounds)\n",
    "            y_pred_valid = model.predict_proba(X_valid)\n",
    "            y_pred = model.predict_proba(X_test, ntree_limit=model.best_ntree_limit)\n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict_proba(X_valid)\n",
    "            score = metrics_dict[eval_metric]['sklearn_scoring_function'](y_valid, y_pred_valid)\n",
    "            print(f'Fold {fold_n}. {eval_metric}: {score:.4f}.')\n",
    "            y_pred = model.predict_proba(X_test)\n",
    "\n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=20000, eval_metric=metrics_dict[eval_metric]['catboost_metric_name'],\n",
    "                                       **params,\n",
    "                                       loss_function=metrics_dict[eval_metric]['catboost_metric_name'])\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True,\n",
    "                      verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict_proba(X_valid)\n",
    "            y_pred = model.predict_proba(X_test)\n",
    "\n",
    "        oof[valid_index] = y_pred_valid\n",
    "        # 评价指标\n",
    "        acc_scores.append(\n",
    "            metrics_dict['lb_score_method']['sklearn_scoring_accuracy'](y_valid, np.argmax(y_pred_valid, axis=1)))\n",
    "        scores.append(\n",
    "            metrics_dict['lb_score_method']['sklearn_scoring_auc'](y_valid, y_pred_valid[:,1]))\n",
    "        f1_scores.append(f1_score(y_valid, [1 if i >= 0.3 else 0 for i in y_pred_valid[:,1]]))\n",
    "        precision_scores.append(precision_score(y_valid, [1 if i >= 0.3 else 0 for i in y_pred_valid[:,1]]))\n",
    "        recall_scores.append(recall_score(y_valid, [1 if i >= 0.3 else 0 for i in y_pred_valid[:,1]]))\n",
    "        print(acc_scores)\n",
    "        print(scores)\n",
    "        print(f1_scores)\n",
    "        print(precision_scores)\n",
    "        print(recall_scores)\n",
    "        prediction += y_pred\n",
    "\n",
    "        if model_type == 'lgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "        if model_type == 'xgb' and plot_feature_importance:\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = columns\n",
    "            fold_importance[\"importance\"] = model.feature_importances_\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "    prediction /= n_splits\n",
    "    print('CV mean auc_score: {0:.8f}, std: {1:.8f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    print('CV mean acc_score: {0:.8f}, std: {1:.8f}.'.format(np.mean(acc_scores), np.std(acc_scores)))\n",
    "    print('CV mean f1_score: {0:.8f}, std: {1:.8f}.'.format(np.mean(f1_scores), np.std(f1_scores)))\n",
    "    print('CV mean precision_score: {0:.8f}, std: {1:.8f}.'.format(np.mean(precision_scores), np.std(precision_scores)))\n",
    "    print('CV mean recall_score: {0:.8f}, std: {1:.8f}.'.format(np.mean(recall_scores), np.std(recall_scores)))\n",
    "\n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['acc_scores'] = acc_scores\n",
    "    result_dict['scores'] = scores\n",
    "    result_dict['f1_scores'] =  f1_scores\n",
    "    result_dict['precision_scores'] =  precision_scores\n",
    "    result_dict['recall_scores'] =  recall_scores\n",
    "\n",
    "\n",
    "    if model_type == 'lgb' or model_type == 'xgb':\n",
    "        if plot_feature_importance:\n",
    "            feature_importance[\"importance\"] /= n_splits\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12))\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "            plt.title('LGB Features (avg over folds)')\n",
    "            plt.show()\n",
    "            result_dict['feature_importance'] = feature_importance\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"train_model_classification cost time:{}\".format(end_time - start_time))\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类个数num_classes:2\n",
      "Fold 1 started at Fri Mar 26 21:07:04 2021\n",
      "[0.8807857142857143]\n",
      "[0.9119007573341835]\n",
      "[0.7020981304596293]\n",
      "[0.6467137915476011]\n",
      "[0.7678571428571429]\n",
      "Fold 2 started at Fri Mar 26 21:15:46 2021\n",
      "[0.8807857142857143, 0.8821071428571429]\n",
      "[0.9119007573341835, 0.9116712452168368]\n",
      "[0.7020981304596293, 0.7036097241548661]\n",
      "[0.6467137915476011, 0.649539066042013]\n",
      "[0.7678571428571429, 0.7675]\n",
      "Fold 3 started at Fri Mar 26 21:24:23 2021\n",
      "[0.8807857142857143, 0.8821071428571429, 0.8828214285714285]\n",
      "[0.9119007573341835, 0.9116712452168368, 0.9133448580994897]\n",
      "[0.7020981304596293, 0.7036097241548661, 0.6985956652325676]\n",
      "[0.6467137915476011, 0.649539066042013, 0.6404226819467183]\n",
      "[0.7678571428571429, 0.7675, 0.7683928571428571]\n",
      "Fold 4 started at Fri Mar 26 21:33:27 2021\n",
      "[0.8807857142857143, 0.8821071428571429, 0.8828214285714285, 0.8809285714285714]\n",
      "[0.9119007573341835, 0.9116712452168368, 0.9133448580994897, 0.9095231584821429]\n",
      "[0.7020981304596293, 0.7036097241548661, 0.6985956652325676, 0.6962356792144027]\n",
      "[0.6467137915476011, 0.649539066042013, 0.6404226819467183, 0.6425981873111782]\n",
      "[0.7678571428571429, 0.7675, 0.7683928571428571, 0.7596428571428572]\n",
      "Fold 5 started at Fri Mar 26 21:43:44 2021\n",
      "[0.8807857142857143, 0.8821071428571429, 0.8828214285714285, 0.8809285714285714, 0.88075]\n",
      "[0.9119007573341835, 0.9116712452168368, 0.9133448580994897, 0.9095231584821429, 0.9073085937500001]\n",
      "[0.7020981304596293, 0.7036097241548661, 0.6985956652325676, 0.6962356792144027, 0.6949901768172888]\n",
      "[0.6467137915476011, 0.649539066042013, 0.6404226819467183, 0.6425981873111782, 0.6416263603385731]\n",
      "[0.7678571428571429, 0.7675, 0.7683928571428571, 0.7596428571428572, 0.7580357142857143]\n",
      "CV mean auc_score: 0.91074972, std: 0.00210972.\n",
      "CV mean acc_score: 0.88147857, std: 0.00083806.\n",
      "CV mean f1_score: 0.69910588, std: 0.00330683.\n",
      "CV mean precision_score: 0.64418002, std: 0.00341410.\n",
      "CV mean recall_score: 0.76428571, std: 0.00448495.\n",
      "train_model_classification cost time:2635.4366006851196\n",
      "0.9107497225765305\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat_params = {'learning_rate': 0.01, 'depth': 8, 'l2_leaf_reg': 6, 'bootstrap_type': 'Bernoulli',\n",
    "              'od_type': 'Iter', 'od_wait': 50, 'random_seed': 1314, 'allow_writing_files': False}\n",
    "n_fold = 5\n",
    "num_classes = 2\n",
    "print(\"分类个数num_classes:{}\".format(num_classes))\n",
    "folds = StratifiedKFold(n_splits=n_fold, random_state=1314)\n",
    "\n",
    "result_dict_cat = train_model_classification(X=X,\n",
    "                                             X_test=X_test,\n",
    "                                             y=y,\n",
    "                                             params=cat_params,\n",
    "                                             num_classes=num_classes,\n",
    "                                             folds=folds,\n",
    "                                             model_type='cat',\n",
    "                                             eval_metric='logloss',\n",
    "                                             plot_feature_importance=False,\n",
    "                                             cat_features=cat_features,\n",
    "                                             verbose=100,\n",
    "                                             early_stopping_rounds=200,\n",
    "                                             n_folds=n_fold)\n",
    "\n",
    "acc_score = np.mean(result_dict_cat['acc_scores'])\n",
    "score = np.mean(result_dict_cat['scores'])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = test_data[['user_id']].copy()\n",
    "sub_df['oof_cat'] = result_dict_cat['prediction'][:, 1]\n",
    "sub_df.to_csv('oof_cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
